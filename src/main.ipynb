{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib as pb\n",
    "\n",
    "# Environment\n",
    "ROOT_PATH = pb.Path('..')\n",
    "DATA_DIR_PATH = ROOT_PATH / 'data'\n",
    "CACHE_DIR_PATH = ROOT_PATH / '.cache'\n",
    "TRANSFORMERS_CACHE_DIR_PATH = CACHE_DIR_PATH / 'transformers'\n",
    "DATASETS_CACHE_DIR_PATH = CACHE_DIR_PATH / 'datasets'\n",
    "TEST_DATA_FILE = DATA_DIR_PATH / 'test_data.csv'\n",
    "TRAIN_DATA_FILE = DATA_DIR_PATH / 'train_data.csv'\n",
    "\n",
    "# Model Repositories\n",
    "BERT_RO_MODEL_REPO = 'dumitrescustefan/bert-base-romanian-cased-v1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "os.environ['TRANSFORMERS_CACHE'] = str(TRANSFORMERS_CACHE_DIR_PATH)\n",
    "os.environ['HF_DATASETS_CACHE'] = str(DATASETS_CACHE_DIR_PATH)\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/invokariman/Projects/git/nitro-lang-processing-2/.cache/pypoetry/virtualenvs/nitro-lang-processing-2-mFR9zZTH-py3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import torchdata\n",
    "import torchtext\n",
    "from torch import Tensor\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import Subset, DataLoader, Dataset\n",
    "from torch import backends\n",
    "import typing\n",
    "import pathlib as pb\n",
    "import os\n",
    "import gc\n",
    "from typing import List, Tuple, Dict, Set\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import platform\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_available_device, read_data\n",
    "from preprocess import BertPreprocessor\n",
    "from data import SexismDataset\n",
    "from models import BertFlatClassModel"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use available GPU\n",
    "DEVICE: torch.device = get_available_device()\n",
    "\n",
    "# Deterministic experiments\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "np.random.RandomState(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.use_deterministic_algorithms(True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_raw, test_data_raw = read_data(DATA_DIR_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SexismDataset(train_data_raw[:1000], BertPreprocessor(train_data_raw, BERT_RO_MODEL_REPO))\n",
    "test_dataset = SexismDataset(test_data_raw[:1000], BertPreprocessor(test_data_raw, BERT_RO_MODEL_REPO))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training specifications\n",
    "batch_size = 16\n",
    "num_epochs = 10\n",
    "num_workers = 1\n",
    "learning_rate = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate language model\n",
    "# Inspired from: https://luv-bansal.medium.com/fine-tuning-bert-for-text-classification-in-pytorch-503d97342db2\n",
    "model = BertFlatClassModel(BERT_RO_MODEL_REPO).to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.CrossEntropyLoss() # TODO: weighted loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/invokariman/Projects/git/nitro-lang-processing-2/.cache/pypoetry/virtualenvs/nitro-lang-processing-2-mFR9zZTH-py3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2184: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/invokariman/Projects/git/nitro-lang-processing-2/.cache/pypoetry/virtualenvs/nitro-lang-processing-2-mFR9zZTH-py3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2184: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/invokariman/Projects/git/nitro-lang-processing-2/.cache/pypoetry/virtualenvs/nitro-lang-processing-2-mFR9zZTH-py3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2184: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/invokariman/Projects/git/nitro-lang-processing-2/.cache/pypoetry/virtualenvs/nitro-lang-processing-2-mFR9zZTH-py3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2184: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/invokariman/Projects/git/nitro-lang-processing-2/.cache/pypoetry/virtualenvs/nitro-lang-processing-2-mFR9zZTH-py3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2184: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/invokariman/Projects/git/nitro-lang-processing-2/.cache/pypoetry/virtualenvs/nitro-lang-processing-2-mFR9zZTH-py3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2184: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Loss: 1.2858831882476807, Accuracy: 0.23703584072931896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/invokariman/Projects/git/nitro-lang-processing-2/.cache/pypoetry/virtualenvs/nitro-lang-processing-2-mFR9zZTH-py3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2184: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Loss: 1.0489047765731812, Accuracy: 0.2717908584169454\n",
      "Epoch 2 - Loss: 0.9518353939056396, Accuracy: 0.2733333333333333\n",
      "Epoch 3 - Loss: 0.9128478765487671, Accuracy: 0.2733333333333333\n",
      "Epoch 4 - Loss: 0.8942375779151917, Accuracy: 0.2733333333333333\n",
      "Epoch 5 - Loss: 0.883380651473999, Accuracy: 0.2733333333333333\n",
      "Epoch 6 - Loss: 0.8758304715156555, Accuracy: 0.2733333333333333\n",
      "Epoch 7 - Loss: 0.8698782324790955, Accuracy: 0.2733333333333333\n",
      "Epoch 8 - Loss: 0.8647992014884949, Accuracy: 0.2733333333333333\n",
      "Epoch 9 - Loss: 0.8602515459060669, Accuracy: 0.2733333333333333\n",
      "Epoch 0 - Loss: 0.8275637030601501, Accuracy: 0.2986666666666667\n",
      "Epoch 1 - Loss: 0.8228095769882202, Accuracy: 0.2986666666666667\n",
      "Epoch 2 - Loss: 0.8186614513397217, Accuracy: 0.2986666666666667\n",
      "Epoch 3 - Loss: 0.8147711157798767, Accuracy: 0.2986666666666667\n",
      "Epoch 4 - Loss: 0.8110924363136292, Accuracy: 0.2986666666666667\n",
      "Epoch 5 - Loss: 0.8075826168060303, Accuracy: 0.2986666666666667\n",
      "Epoch 6 - Loss: 0.8042057156562805, Accuracy: 0.2986666666666667\n",
      "Epoch 7 - Loss: 0.8009397983551025, Accuracy: 0.2986666666666667\n",
      "Epoch 8 - Loss: 0.7977710962295532, Accuracy: 0.2986666666666667\n",
      "Epoch 9 - Loss: 0.7946896553039551, Accuracy: 0.2986666666666667\n",
      "Epoch 0 - Loss: 0.8370402455329895, Accuracy: 0.2866666666666666\n",
      "Epoch 1 - Loss: 0.8316994309425354, Accuracy: 0.2866666666666666\n",
      "Epoch 2 - Loss: 0.8272674679756165, Accuracy: 0.2866666666666666\n",
      "Epoch 3 - Loss: 0.8235222101211548, Accuracy: 0.2866666666666666\n",
      "Epoch 4 - Loss: 0.8200985789299011, Accuracy: 0.2866666666666666\n",
      "Epoch 5 - Loss: 0.8168639540672302, Accuracy: 0.2866666666666666\n",
      "Epoch 6 - Loss: 0.813764750957489, Accuracy: 0.2866666666666666\n",
      "Epoch 7 - Loss: 0.8107689023017883, Accuracy: 0.2866666666666666\n",
      "Epoch 8 - Loss: 0.8078567981719971, Accuracy: 0.2866666666666666\n",
      "Epoch 9 - Loss: 0.8050164580345154, Accuracy: 0.2866666666666666\n",
      "Epoch 0 - Loss: 0.781497597694397, Accuracy: 0.28733333333333333\n",
      "Epoch 1 - Loss: 0.777488648891449, Accuracy: 0.28733333333333333\n",
      "Epoch 2 - Loss: 0.7743823528289795, Accuracy: 0.28733333333333333\n",
      "Epoch 3 - Loss: 0.7715556621551514, Accuracy: 0.28733333333333333\n",
      "Epoch 4 - Loss: 0.7689945697784424, Accuracy: 0.28733333333333333\n",
      "Epoch 5 - Loss: 0.766629695892334, Accuracy: 0.28733333333333333\n",
      "Epoch 6 - Loss: 0.7643773555755615, Accuracy: 0.28733333333333333\n",
      "Epoch 7 - Loss: 0.762195885181427, Accuracy: 0.28733333333333333\n",
      "Epoch 8 - Loss: 0.7600669860839844, Accuracy: 0.28733333333333333\n",
      "Epoch 9 - Loss: 0.7579810619354248, Accuracy: 0.28733333333333333\n",
      "Epoch 0 - Loss: 0.7766978740692139, Accuracy: 0.29066666666666663\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 39\u001b[0m\n\u001b[1;32m     36\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     38\u001b[0m \u001b[39m# Compute the accuracy\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m y_true \u001b[39m=\u001b[39m y_true\u001b[39m.\u001b[39;49mdetach()\u001b[39m.\u001b[39;49mcpu()\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m     40\u001b[0m y_pred \u001b[39m=\u001b[39m y_pred\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39margmax(dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m     41\u001b[0m epoch_accy\u001b[39m.\u001b[39mappend(balanced_accuracy_score(y_true, y_pred))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Inspired from: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "\n",
    "for i, (train_idx, valid_idx) in enumerate(kf.split(train_dataset)):\n",
    "    # Split the data\n",
    "    train_subset = Subset(train_dataset, train_idx)\n",
    "    valid_subset = Subset(train_dataset, valid_idx)\n",
    "\n",
    "    # Create the dataloaders\n",
    "    train_loader = DataLoader(\n",
    "        train_subset,\n",
    "        batch_size,\n",
    "    )\n",
    "    valid_loader = DataLoader(\n",
    "        train_subset,\n",
    "        batch_size,\n",
    "    )\n",
    "\n",
    "    # ---  Training  ---\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = []\n",
    "        epoch_accy = []\n",
    "\n",
    "        for batch_i, batch in enumerate(train_loader):\n",
    "            # Send batch to GPU\n",
    "            batch: Dict[str, Tensor] = { k: v.to(DEVICE) for k, v in batch.items()}\n",
    "\n",
    "            # Make predictions\n",
    "            y_true: Tensor | np.ndarray = batch['label']\n",
    "            y_pred: Tensor | np.ndarray = model.forward(batch)\n",
    "\n",
    "            # Compute the loss\n",
    "            optimizer.zero_grad()\n",
    "            loss: Tensor = loss_fn(y_pred, y_true)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Compute the accuracy\n",
    "            y_true = y_true.detach().cpu().numpy()\n",
    "            y_pred = y_pred.detach().argmax(dim=1).cpu().numpy()\n",
    "            epoch_accy.append(balanced_accuracy_score(y_true, y_pred))\n",
    "\n",
    "            # Track progress\n",
    "            epoch_loss.append(loss.detach().cpu().numpy())\n",
    "\n",
    "        mean_loss = np.array(epoch_loss).mean()\n",
    "        mean_accy = np.array(epoch_accy).mean()\n",
    "        print('Epoch {} - Loss: {}, Accuracy: {}'.format(epoch, mean_loss, mean_accy))\n",
    "\n",
    "    # --- Validation ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_accuracy_score(y_true.detach().cpu().numpy(), y_pred.argmax(dim=1).detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 0, 0, 3, 3, 3, 3, 3, 3, 4, 3, 3, 3, 3, 0, 4, 3, 3, 1, 3, 3, 3, 3, 3,\n",
       "        3, 3, 3, 3, 3, 0, 1, 3], device='cuda:0')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 5]) tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(y_pred.shape, y_pred.argmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free memory\n",
    "del model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nitro-lang-processing-2-mFR9zZTH-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
